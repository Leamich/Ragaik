{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c18d6f1a-bcbd-4248-aeaa-728391948116",
   "metadata": {},
   "source": [
    "# Used datasets are:\n",
    "- [russian writing](https://github.com/ZackPashkin/Cyrillic-Handwriting-Dataset?tab=readme-ov-file) \n",
    "- [math formulas](https://researchdata.edu.au/crohme-competition-recognition-expressions-png/639782)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea986c9b-e784-4e6d-ad29-0e0dfeda80f7",
   "metadata": {},
   "source": [
    "### At first, we need to separate photos white (the most supreme color) backround from others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7584bea-ac89-4fd5-b8a5-f12b1b60d466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import argparse\n",
    "import numpy as np\n",
    "from numpy import typing as np_typing\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1105d29d-ef9b-402d-b4b4-3ff169bda8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "WHITENESS_THRESH = 220\n",
    "WHITE_PERCENT = 0.87\n",
    "\n",
    "def count_white_pixels(pixels: np_typing.NDArray) -> int:\n",
    "    return  np.sum(np.all(pixels >= WHITENESS_THRESH, axis=2))\n",
    "    \n",
    "\n",
    "\n",
    "def is_white(image_path: str) -> bool:\n",
    "    with Image.open(image_path) as im:\n",
    "        im = im.convert(\"RGB\")\n",
    "        pixels = np.array(im)\n",
    "    total_pixels = pixels.shape[0] * pixels.shape[1]\n",
    "    white_pixels = count_white_pixels(pixels)\n",
    "    return (white_pixels / total_pixels) >= WHITE_PERCENT\n",
    "\n",
    "EXTENSIONS = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\", \".gif\")\n",
    "EXTENSIONS_S = set(EXTENSIONS)\n",
    "\n",
    "\n",
    "def filter(from_dir: str, to_dir: str) -> None:\n",
    "    os.makedirs(to_dir, exist_ok=True)\n",
    "    \n",
    "    for root, _, files in os.walk(from_dir):\n",
    "        for fname in files:\n",
    "            if not fname.lower().endswith(EXTENSIONS):\n",
    "                continue\n",
    "            src = os.path.join(root, fname)\n",
    "            try:\n",
    "                if is_white(src):\n",
    "                    dst = os.path.join(to_dir, fname)\n",
    "                    shutil.copy2(src, dst)\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping {src}: {e}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45327555-d17a-4894-afcf-db98fb1e069b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter('data/math', 'data/math_out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959ea393-05b2-40c3-a1ea-74e04918ac88",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter('data/russian', 'data/russian_out')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8277aa-5d15-46b8-8f11-521d7d043757",
   "metadata": {},
   "source": [
    "### Then combine the shit into one images (and also generate labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "504da638-ff3a-4eb3-b493-8e123b8f6f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "CANVAS_SIZE = (1920, 1080)\n",
    "COUNT_PER_SAMPLE = 6\n",
    "MIN_RANDOM_SCALE = 0.5\n",
    "MAX_RANDOM_SCALE = 1.0\n",
    "\n",
    "MAX_ATTEMPTS = 10\n",
    "\n",
    "RUSSIAN_SCALE = 1.4\n",
    "MATH_SCALE = 0.25\n",
    "\n",
    "def generate_composite(\n",
    "    imgs_A, imgs_B, out_dir, idx,\n",
    "):\n",
    "    canvas_w, canvas_h = CANVAS_SIZE\n",
    " \n",
    "    canvas = Image.new(\"RGB\", CANVAS_SIZE, (255, 255, 255))\n",
    "\n",
    "    bboxes = []\n",
    "    placements = []\n",
    "\n",
    "    def place_list(img_paths, class_idx, scale_factor=1.0):\n",
    "        samples = (random.sample(img_paths, COUNT_PER_SAMPLE)\n",
    "                   if COUNT_PER_SAMPLE <= len(img_paths)\n",
    "                   else random.choices(img_paths, k=COUNT_PER_SAMPLE))\n",
    "        for img_path in samples:\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            iw, ih = img.size\n",
    "            max_fit = min(canvas_w/iw, canvas_h/ih, 1.0)\n",
    "            scale = random.uniform(MIN_RANDOM_SCALE, MAX_RANDOM_SCALE) * max_fit\n",
    "            nw, nh = int(iw*scale*scale_factor), int(ih*scale*scale_factor)\n",
    "            if nw < 1 or nh < 1:\n",
    "                continue\n",
    "            img_resized = img.resize((nw, nh))\n",
    "            for _ in range(MAX_ATTEMPTS):\n",
    "                attempts = 0\n",
    "               \n",
    "                x = random.randint(0, canvas_w-nw)\n",
    "                y = random.randint(0, canvas_h-nh)\n",
    "                rect = (x, y, x+nw, y+nh)\n",
    "                if not any(\n",
    "                    rect[0]<ox2 and rect[2]>ox1 and rect[1]<oy2 and rect[3]>oy1\n",
    "                    for (ox1,oy1,ox2,oy2) in placements\n",
    "                ):\n",
    "                    canvas.paste(img_resized, (x, y))\n",
    "                    placements.append(rect)\n",
    "                    xc = (x+nw/2)/canvas_w\n",
    "                    yc = (y+nh/2)/canvas_h\n",
    "                    bboxes.append((class_idx, xc, yc, nw/canvas_w, nh/canvas_h))\n",
    "                    break\n",
    "                    \n",
    "                \n",
    "    place_list(imgs_A, class_idx=0, scale_factor=RUSSIAN_SCALE)\n",
    "    place_list(imgs_B, class_idx=1, scale_factor=MATH_SCALE)\n",
    "\n",
    "    img_name = f\"img_{idx:05d}.jpg\"\n",
    "    label_name = f\"img_{idx:05d}.txt\"\n",
    "    canvas.save(os.path.join(out_dir, img_name), quality=95)\n",
    "    with open(os.path.join(out_dir, label_name), 'w') as lf:\n",
    "        for cls, xc, yc, w, h in bboxes:\n",
    "            lf.write(f\"{cls} {xc:.6f} {yc:.6f} {w:.6f} {h:.6f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca25c606-426b-4769-856b-08724e3c69c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_images(folder: str):\n",
    "    return [os.path.join(folder, f) for f in os.listdir(folder)\n",
    "             if os.path.splitext(f.lower())[1] in EXTENSIONS_S]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d5ad36d-3e7b-496b-82b7-96ac423a1a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(russian, math, out, n_samples=4):\n",
    "    os.makedirs(out, exist_ok=True)\n",
    "    imgs_A = collect_images(russian)\n",
    "    imgsB = collect_images(math)\n",
    "    imgs_B = imgsB[:len(imgs_A)]\n",
    "\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        generate_composite(imgs_A, imgs_B, out, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b0d93051-008c-4294-8524-9b57ad8c7398",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate('data/russian_out', 'data/math_out', \"data/out_out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bbc1a3-3ca8-4899-94f0-d133ff6941e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
